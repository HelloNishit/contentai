spring.application.name=contentai
spring.threads.virtual.enabled=true
spring.servlet.multipart.enabled=true


spring.datasource.url=jdbc:postgresql://localhost:5455/contentai
spring.datasource.username=postgres
spring.datasource.password=postgres
spring.datasource.ai.vectorstore.pgvector.index-type=HNSW
spring.datasource.ai.vectorstore.pgvector.distance-type=COSINE_DISTANCE
spring.datasource.ai.vectorstore.pgvector.dimensions=1536
spring.datasource.ai.vectorstore.pgvector.max-document-batch-size=10000 # Optional: Maximum number of documents per batch

# Deletes the existing vector_store table on start up.
spring.ai.vectorstore.pgvector.remove-existing-vector-store-table=true

# Whether to initialize the required schema
spring.ai.vectorstore.pgvector.initialize-schema=true


# Controls when to initialize the schema. Values: embedded (default), always, never.
spring.ai.chat.memory.repository.jdbc.initialize-schema=always

spring.jpa.hibernate.ddl-auto=create


#spring.ai.ollama.base-url=http://192.168.0.160:11434

#spring.ai.ollama.base-url=http://192.168.101.248:11434
spring.ai.ollama.chat.enabled=false
#spring.ai.ollama.chat.options.model=llama3.2:latest
#spring.ai.ollama.chat.options.model=gemma3:latest
#spring.ai.ollama.chat.options.model=gemma2:2b
#spring.autoconfigure.exclude=org.springframework.ai.model.openai.autoconfigure.OpenAiEmbeddingAutoConfiguration,OllamaChatAutoConfiguration

spring.ai.openai.api-key=gsk_ck6FSWoiUz9ny700lrfFWGdyb3FYfYEygfRaIOfivWSbvb6zUppk_EocZt
spring.ai.openai.base-url=https://api.groq.com/openai
spring.ai.openai.chat.options.model=llama-3.1-8b-instant
spring.ai.openai.chat.model=meta-llama/llama-guard-4-12b
spring.ai.openai.chat.options.temperature=0.7

spring.ai.ollama.embedding.base-url=http://localhost:11434
spring.ai.ollama.embedding.options.model=mxbai-embed-large
#spring.ai.openai.embedding.options.model=text-embedding-3-small
spring.ai.openai.embedding=none

# number of CPU cores to use
spring.ai.ollama.chat.options.num-thread=4

#Reduces the probability of generating nonsense. A higher value (e.g., 100) will give more diverse answers, while a lower value (e.g., 10) will be more conservative.
spring.ai.ollama.chat.options.top-k=35

#Works together with top-k. A higher value (e.g., 0.95) will lead to more diverse text, while a lower value (e.g., 0.5) will generate more focused and conservative text.
spring.ai.ollama.chat.options.top-p=0.8
